{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script implements a simple RNN model for the Music Genre Classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1229 00:16:35.822873 140281217849088 __init__.py:321] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "W1229 00:16:35.851773 140281217849088 __init__.py:321] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "W1229 00:16:35.867061 140281217849088 __init__.py:352] Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "# System/zip-handling imports\n",
    "import os, sys\n",
    "import zipfile\n",
    "\n",
    "# Imports tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, regularizers\n",
    "\n",
    "# Imports image handling\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "\n",
    "# For generating training and test data\n",
    "import random\n",
    "\n",
    "# Save training progress\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from shutil import copyfile  # Making copy of this file instance (including param settings used)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get sorted list of training file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spectrograms/spectrogram_0000.png', 'spectrograms/spectrogram_0001.png', 'spectrograms/spectrogram_0002.png', 'spectrograms/spectrogram_0003.png', 'spectrograms/spectrogram_0004.png', 'spectrograms/spectrogram_0005.png', 'spectrograms/spectrogram_0006.png', 'spectrograms/spectrogram_0007.png', 'spectrograms/spectrogram_0008.png', 'spectrograms/spectrogram_0009.png', 'spectrograms/spectrogram_0010.png', 'spectrograms/spectrogram_0011.png', 'spectrograms/spectrogram_0012.png', 'spectrograms/spectrogram_0013.png', 'spectrograms/spectrogram_0014.png', 'spectrograms/spectrogram_0015.png', 'spectrograms/spectrogram_0016.png', 'spectrograms/spectrogram_0017.png', 'spectrograms/spectrogram_0018.png', 'spectrograms/spectrogram_0019.png', 'spectrograms/spectrogram_0020.png', 'spectrograms/spectrogram_0021.png', 'spectrograms/spectrogram_0022.png', 'spectrograms/spectrogram_0023.png', 'spectrograms/spectrogram_0024.png', 'spectrograms/spectrogram_0025.png', 'spectrograms/spectrogram_0026.png', 'spectrograms/spectrogram_0027.png', 'spectrograms/spectrogram_0028.png', 'spectrograms/spectrogram_0029.png', 'spectrograms/spectrogram_0030.png', 'spectrograms/spectrogram_0031.png', 'spectrograms/spectrogram_0032.png', 'spectrograms/spectrogram_0033.png', 'spectrograms/spectrogram_0034.png', 'spectrograms/spectrogram_0035.png', 'spectrograms/spectrogram_0036.png', 'spectrograms/spectrogram_0037.png', 'spectrograms/spectrogram_0038.png', 'spectrograms/spectrogram_0039.png', 'spectrograms/spectrogram_0040.png', 'spectrograms/spectrogram_0041.png', 'spectrograms/spectrogram_0042.png', 'spectrograms/spectrogram_0043.png', 'spectrograms/spectrogram_0044.png', 'spectrograms/spectrogram_0045.png', 'spectrograms/spectrogram_0046.png', 'spectrograms/spectrogram_0047.png', 'spectrograms/spectrogram_0048.png', 'spectrograms/spectrogram_0049.png', 'spectrograms/spectrogram_0050.png', 'spectrograms/spectrogram_0051.png', 'spectrograms/spectrogram_0052.png', 'spectrograms/spectrogram_0053.png', 'spectrograms/spectrogram_0054.png', 'spectrograms/spectrogram_0055.png', 'spectrograms/spectrogram_0056.png', 'spectrograms/spectrogram_0057.png', 'spectrograms/spectrogram_0058.png', 'spectrograms/spectrogram_0059.png', 'spectrograms/spectrogram_0060.png', 'spectrograms/spectrogram_0061.png', 'spectrograms/spectrogram_0062.png', 'spectrograms/spectrogram_0063.png', 'spectrograms/spectrogram_0064.png', 'spectrograms/spectrogram_0065.png', 'spectrograms/spectrogram_0066.png', 'spectrograms/spectrogram_0067.png', 'spectrograms/spectrogram_0068.png', 'spectrograms/spectrogram_0069.png', 'spectrograms/spectrogram_0070.png', 'spectrograms/spectrogram_0071.png', 'spectrograms/spectrogram_0072.png', 'spectrograms/spectrogram_0073.png', 'spectrograms/spectrogram_0074.png', 'spectrograms/spectrogram_0075.png', 'spectrograms/spectrogram_0076.png', 'spectrograms/spectrogram_0077.png', 'spectrograms/spectrogram_0078.png', 'spectrograms/spectrogram_0079.png', 'spectrograms/spectrogram_0080.png', 'spectrograms/spectrogram_0081.png', 'spectrograms/spectrogram_0082.png', 'spectrograms/spectrogram_0083.png', 'spectrograms/spectrogram_0084.png', 'spectrograms/spectrogram_0085.png', 'spectrograms/spectrogram_0086.png', 'spectrograms/spectrogram_0087.png', 'spectrograms/spectrogram_0088.png', 'spectrograms/spectrogram_0089.png', 'spectrograms/spectrogram_0090.png', 'spectrograms/spectrogram_0091.png', 'spectrograms/spectrogram_0092.png', 'spectrograms/spectrogram_0093.png', 'spectrograms/spectrogram_0094.png', 'spectrograms/spectrogram_0095.png', 'spectrograms/spectrogram_0096.png', 'spectrograms/spectrogram_0097.png', 'spectrograms/spectrogram_0098.png', 'spectrograms/spectrogram_0099.png', 'spectrograms/spectrogram_0100.png', 'spectrograms/spectrogram_0101.png', 'spectrograms/spectrogram_0102.png', 'spectrograms/spectrogram_0103.png', 'spectrograms/spectrogram_0104.png', 'spectrograms/spectrogram_0105.png', 'spectrograms/spectrogram_0106.png', 'spectrograms/spectrogram_0107.png', 'spectrograms/spectrogram_0108.png', 'spectrograms/spectrogram_0109.png', 'spectrograms/spectrogram_0110.png', 'spectrograms/spectrogram_0111.png', 'spectrograms/spectrogram_0112.png', 'spectrograms/spectrogram_0113.png', 'spectrograms/spectrogram_0114.png', 'spectrograms/spectrogram_0115.png', 'spectrograms/spectrogram_0116.png', 'spectrograms/spectrogram_0117.png', 'spectrograms/spectrogram_0118.png', 'spectrograms/spectrogram_0119.png', 'spectrograms/spectrogram_0120.png', 'spectrograms/spectrogram_0121.png', 'spectrograms/spectrogram_0122.png', 'spectrograms/spectrogram_0123.png', 'spectrograms/spectrogram_0124.png', 'spectrograms/spectrogram_0125.png', 'spectrograms/spectrogram_0126.png', 'spectrograms/spectrogram_0127.png', 'spectrograms/spectrogram_0128.png', 'spectrograms/spectrogram_0129.png', 'spectrograms/spectrogram_0130.png', 'spectrograms/spectrogram_0131.png', 'spectrograms/spectrogram_0132.png', 'spectrograms/spectrogram_0133.png', 'spectrograms/spectrogram_0134.png', 'spectrograms/spectrogram_0135.png', 'spectrograms/spectrogram_0136.png', 'spectrograms/spectrogram_0137.png', 'spectrograms/spectrogram_0138.png', 'spectrograms/spectrogram_0139.png', 'spectrograms/spectrogram_0140.png', 'spectrograms/spectrogram_0141.png', 'spectrograms/spectrogram_0142.png', 'spectrograms/spectrogram_0143.png', 'spectrograms/spectrogram_0144.png', 'spectrograms/spectrogram_0145.png', 'spectrograms/spectrogram_0146.png', 'spectrograms/spectrogram_0147.png', 'spectrograms/spectrogram_0148.png', 'spectrograms/spectrogram_0149.png', 'spectrograms/spectrogram_0150.png', 'spectrograms/spectrogram_0151.png', 'spectrograms/spectrogram_0152.png', 'spectrograms/spectrogram_0153.png', 'spectrograms/spectrogram_0154.png', 'spectrograms/spectrogram_0155.png', 'spectrograms/spectrogram_0156.png', 'spectrograms/spectrogram_0157.png', 'spectrograms/spectrogram_0158.png', 'spectrograms/spectrogram_0159.png', 'spectrograms/spectrogram_0160.png', 'spectrograms/spectrogram_0161.png', 'spectrograms/spectrogram_0162.png', 'spectrograms/spectrogram_0163.png', 'spectrograms/spectrogram_0164.png', 'spectrograms/spectrogram_0165.png', 'spectrograms/spectrogram_0166.png', 'spectrograms/spectrogram_0167.png', 'spectrograms/spectrogram_0168.png', 'spectrograms/spectrogram_0169.png', 'spectrograms/spectrogram_0170.png', 'spectrograms/spectrogram_0171.png', 'spectrograms/spectrogram_0172.png', 'spectrograms/spectrogram_0173.png', 'spectrograms/spectrogram_0174.png', 'spectrograms/spectrogram_0175.png', 'spectrograms/spectrogram_0176.png', 'spectrograms/spectrogram_0177.png', 'spectrograms/spectrogram_0178.png', 'spectrograms/spectrogram_0179.png', 'spectrograms/spectrogram_0180.png', 'spectrograms/spectrogram_0181.png', 'spectrograms/spectrogram_0182.png', 'spectrograms/spectrogram_0183.png', 'spectrograms/spectrogram_0184.png', 'spectrograms/spectrogram_0185.png', 'spectrograms/spectrogram_0186.png', 'spectrograms/spectrogram_0187.png', 'spectrograms/spectrogram_0188.png', 'spectrograms/spectrogram_0189.png', 'spectrograms/spectrogram_0190.png', 'spectrograms/spectrogram_0191.png', 'spectrograms/spectrogram_0192.png', 'spectrograms/spectrogram_0193.png', 'spectrograms/spectrogram_0194.png', 'spectrograms/spectrogram_0195.png', 'spectrograms/spectrogram_0196.png', 'spectrograms/spectrogram_0197.png', 'spectrograms/spectrogram_0198.png', 'spectrograms/spectrogram_0199.png', 'spectrograms/spectrogram_0200.png', 'spectrograms/spectrogram_0201.png', 'spectrograms/spectrogram_0202.png', 'spectrograms/spectrogram_0203.png', 'spectrograms/spectrogram_0204.png', 'spectrograms/spectrogram_0205.png', 'spectrograms/spectrogram_0206.png', 'spectrograms/spectrogram_0207.png', 'spectrograms/spectrogram_0208.png', 'spectrograms/spectrogram_0209.png', 'spectrograms/spectrogram_0210.png', 'spectrograms/spectrogram_0211.png', 'spectrograms/spectrogram_0212.png', 'spectrograms/spectrogram_0213.png', 'spectrograms/spectrogram_0214.png', 'spectrograms/spectrogram_0215.png', 'spectrograms/spectrogram_0216.png', 'spectrograms/spectrogram_0217.png', 'spectrograms/spectrogram_0218.png', 'spectrograms/spectrogram_0219.png', 'spectrograms/spectrogram_0220.png', 'spectrograms/spectrogram_0221.png', 'spectrograms/spectrogram_0222.png', 'spectrograms/spectrogram_0223.png', 'spectrograms/spectrogram_0224.png', 'spectrograms/spectrogram_0225.png', 'spectrograms/spectrogram_0226.png', 'spectrograms/spectrogram_0227.png', 'spectrograms/spectrogram_0228.png', 'spectrograms/spectrogram_0229.png', 'spectrograms/spectrogram_0230.png', 'spectrograms/spectrogram_0231.png', 'spectrograms/spectrogram_0232.png', 'spectrograms/spectrogram_0233.png', 'spectrograms/spectrogram_0234.png', 'spectrograms/spectrogram_0235.png', 'spectrograms/spectrogram_0236.png', 'spectrograms/spectrogram_0237.png', 'spectrograms/spectrogram_0238.png', 'spectrograms/spectrogram_0239.png', 'spectrograms/spectrogram_0240.png', 'spectrograms/spectrogram_0241.png', 'spectrograms/spectrogram_0242.png', 'spectrograms/spectrogram_0243.png', 'spectrograms/spectrogram_0244.png', 'spectrograms/spectrogram_0245.png', 'spectrograms/spectrogram_0246.png', 'spectrograms/spectrogram_0247.png', 'spectrograms/spectrogram_0248.png', 'spectrograms/spectrogram_0249.png', 'spectrograms/spectrogram_0250.png', 'spectrograms/spectrogram_0251.png', 'spectrograms/spectrogram_0252.png', 'spectrograms/spectrogram_0253.png', 'spectrograms/spectrogram_0254.png', 'spectrograms/spectrogram_0255.png', 'spectrograms/spectrogram_0256.png', 'spectrograms/spectrogram_0257.png', 'spectrograms/spectrogram_0258.png', 'spectrograms/spectrogram_0259.png', 'spectrograms/spectrogram_0260.png', 'spectrograms/spectrogram_0261.png', 'spectrograms/spectrogram_0262.png', 'spectrograms/spectrogram_0263.png', 'spectrograms/spectrogram_0264.png', 'spectrograms/spectrogram_0265.png', 'spectrograms/spectrogram_0266.png', 'spectrograms/spectrogram_0267.png', 'spectrograms/spectrogram_0268.png', 'spectrograms/spectrogram_0269.png', 'spectrograms/spectrogram_0270.png', 'spectrograms/spectrogram_0271.png', 'spectrograms/spectrogram_0272.png', 'spectrograms/spectrogram_0273.png', 'spectrograms/spectrogram_0274.png', 'spectrograms/spectrogram_0275.png', 'spectrograms/spectrogram_0276.png', 'spectrograms/spectrogram_0277.png', 'spectrograms/spectrogram_0278.png', 'spectrograms/spectrogram_0279.png', 'spectrograms/spectrogram_0280.png', 'spectrograms/spectrogram_0281.png', 'spectrograms/spectrogram_0282.png', 'spectrograms/spectrogram_0283.png', 'spectrograms/spectrogram_0284.png', 'spectrograms/spectrogram_0285.png', 'spectrograms/spectrogram_0286.png', 'spectrograms/spectrogram_0287.png', 'spectrograms/spectrogram_0288.png', 'spectrograms/spectrogram_0289.png', 'spectrograms/spectrogram_0290.png', 'spectrograms/spectrogram_0291.png', 'spectrograms/spectrogram_0292.png', 'spectrograms/spectrogram_0293.png', 'spectrograms/spectrogram_0294.png', 'spectrograms/spectrogram_0295.png', 'spectrograms/spectrogram_0296.png', 'spectrograms/spectrogram_0297.png', 'spectrograms/spectrogram_0298.png', 'spectrograms/spectrogram_0299.png', 'spectrograms/spectrogram_0300.png', 'spectrograms/spectrogram_0301.png', 'spectrograms/spectrogram_0302.png', 'spectrograms/spectrogram_0303.png', 'spectrograms/spectrogram_0304.png', 'spectrograms/spectrogram_0305.png', 'spectrograms/spectrogram_0306.png', 'spectrograms/spectrogram_0307.png', 'spectrograms/spectrogram_0308.png', 'spectrograms/spectrogram_0309.png', 'spectrograms/spectrogram_0310.png', 'spectrograms/spectrogram_0311.png', 'spectrograms/spectrogram_0312.png', 'spectrograms/spectrogram_0313.png', 'spectrograms/spectrogram_0314.png', 'spectrograms/spectrogram_0315.png', 'spectrograms/spectrogram_0316.png', 'spectrograms/spectrogram_0317.png', 'spectrograms/spectrogram_0318.png', 'spectrograms/spectrogram_0319.png', 'spectrograms/spectrogram_0320.png', 'spectrograms/spectrogram_0321.png', 'spectrograms/spectrogram_0322.png', 'spectrograms/spectrogram_0323.png', 'spectrograms/spectrogram_0324.png', 'spectrograms/spectrogram_0325.png', 'spectrograms/spectrogram_0326.png', 'spectrograms/spectrogram_0327.png', 'spectrograms/spectrogram_0328.png', 'spectrograms/spectrogram_0329.png', 'spectrograms/spectrogram_0330.png', 'spectrograms/spectrogram_0331.png', 'spectrograms/spectrogram_0332.png', 'spectrograms/spectrogram_0333.png', 'spectrograms/spectrogram_0334.png', 'spectrograms/spectrogram_0335.png', 'spectrograms/spectrogram_0336.png', 'spectrograms/spectrogram_0337.png', 'spectrograms/spectrogram_0338.png', 'spectrograms/spectrogram_0339.png', 'spectrograms/spectrogram_0340.png', 'spectrograms/spectrogram_0341.png', 'spectrograms/spectrogram_0342.png', 'spectrograms/spectrogram_0343.png', 'spectrograms/spectrogram_0344.png', 'spectrograms/spectrogram_0345.png', 'spectrograms/spectrogram_0346.png', 'spectrograms/spectrogram_0347.png', 'spectrograms/spectrogram_0348.png', 'spectrograms/spectrogram_0349.png', 'spectrograms/spectrogram_0350.png', 'spectrograms/spectrogram_0351.png', 'spectrograms/spectrogram_0352.png', 'spectrograms/spectrogram_0353.png', 'spectrograms/spectrogram_0354.png', 'spectrograms/spectrogram_0355.png', 'spectrograms/spectrogram_0356.png', 'spectrograms/spectrogram_0357.png', 'spectrograms/spectrogram_0358.png', 'spectrograms/spectrogram_0359.png', 'spectrograms/spectrogram_0360.png', 'spectrograms/spectrogram_0361.png', 'spectrograms/spectrogram_0362.png', 'spectrograms/spectrogram_0363.png', 'spectrograms/spectrogram_0364.png', 'spectrograms/spectrogram_0365.png', 'spectrograms/spectrogram_0366.png', 'spectrograms/spectrogram_0367.png', 'spectrograms/spectrogram_0368.png', 'spectrograms/spectrogram_0369.png', 'spectrograms/spectrogram_0370.png', 'spectrograms/spectrogram_0371.png', 'spectrograms/spectrogram_0372.png', 'spectrograms/spectrogram_0373.png', 'spectrograms/spectrogram_0374.png', 'spectrograms/spectrogram_0375.png', 'spectrograms/spectrogram_0376.png', 'spectrograms/spectrogram_0377.png', 'spectrograms/spectrogram_0378.png', 'spectrograms/spectrogram_0379.png', 'spectrograms/spectrogram_0380.png', 'spectrograms/spectrogram_0381.png', 'spectrograms/spectrogram_0382.png', 'spectrograms/spectrogram_0383.png', 'spectrograms/spectrogram_0384.png', 'spectrograms/spectrogram_0385.png', 'spectrograms/spectrogram_0386.png', 'spectrograms/spectrogram_0387.png', 'spectrograms/spectrogram_0388.png', 'spectrograms/spectrogram_0389.png', 'spectrograms/spectrogram_0390.png', 'spectrograms/spectrogram_0391.png', 'spectrograms/spectrogram_0392.png', 'spectrograms/spectrogram_0393.png', 'spectrograms/spectrogram_0394.png', 'spectrograms/spectrogram_0395.png', 'spectrograms/spectrogram_0396.png', 'spectrograms/spectrogram_0397.png', 'spectrograms/spectrogram_0398.png', 'spectrograms/spectrogram_0399.png', 'spectrograms/spectrogram_0400.png', 'spectrograms/spectrogram_0401.png', 'spectrograms/spectrogram_0402.png', 'spectrograms/spectrogram_0403.png', 'spectrograms/spectrogram_0404.png', 'spectrograms/spectrogram_0405.png', 'spectrograms/spectrogram_0406.png', 'spectrograms/spectrogram_0407.png', 'spectrograms/spectrogram_0408.png', 'spectrograms/spectrogram_0409.png', 'spectrograms/spectrogram_0410.png', 'spectrograms/spectrogram_0411.png', 'spectrograms/spectrogram_0412.png', 'spectrograms/spectrogram_0413.png', 'spectrograms/spectrogram_0414.png', 'spectrograms/spectrogram_0415.png', 'spectrograms/spectrogram_0416.png', 'spectrograms/spectrogram_0417.png', 'spectrograms/spectrogram_0418.png', 'spectrograms/spectrogram_0419.png', 'spectrograms/spectrogram_0420.png', 'spectrograms/spectrogram_0421.png', 'spectrograms/spectrogram_0422.png', 'spectrograms/spectrogram_0423.png', 'spectrograms/spectrogram_0424.png', 'spectrograms/spectrogram_0425.png', 'spectrograms/spectrogram_0426.png', 'spectrograms/spectrogram_0427.png', 'spectrograms/spectrogram_0428.png', 'spectrograms/spectrogram_0429.png', 'spectrograms/spectrogram_0430.png', 'spectrograms/spectrogram_0431.png', 'spectrograms/spectrogram_0432.png', 'spectrograms/spectrogram_0433.png', 'spectrograms/spectrogram_0434.png', 'spectrograms/spectrogram_0435.png', 'spectrograms/spectrogram_0436.png', 'spectrograms/spectrogram_0437.png', 'spectrograms/spectrogram_0438.png', 'spectrograms/spectrogram_0439.png', 'spectrograms/spectrogram_0440.png', 'spectrograms/spectrogram_0441.png', 'spectrograms/spectrogram_0442.png', 'spectrograms/spectrogram_0443.png', 'spectrograms/spectrogram_0444.png', 'spectrograms/spectrogram_0445.png', 'spectrograms/spectrogram_0446.png', 'spectrograms/spectrogram_0447.png', 'spectrograms/spectrogram_0448.png', 'spectrograms/spectrogram_0449.png', 'spectrograms/spectrogram_0450.png', 'spectrograms/spectrogram_0451.png', 'spectrograms/spectrogram_0452.png', 'spectrograms/spectrogram_0453.png', 'spectrograms/spectrogram_0454.png', 'spectrograms/spectrogram_0455.png', 'spectrograms/spectrogram_0456.png', 'spectrograms/spectrogram_0457.png', 'spectrograms/spectrogram_0458.png', 'spectrograms/spectrogram_0459.png', 'spectrograms/spectrogram_0460.png', 'spectrograms/spectrogram_0461.png', 'spectrograms/spectrogram_0462.png', 'spectrograms/spectrogram_0463.png', 'spectrograms/spectrogram_0464.png', 'spectrograms/spectrogram_0465.png', 'spectrograms/spectrogram_0466.png', 'spectrograms/spectrogram_0467.png', 'spectrograms/spectrogram_0468.png', 'spectrograms/spectrogram_0469.png', 'spectrograms/spectrogram_0470.png', 'spectrograms/spectrogram_0471.png', 'spectrograms/spectrogram_0472.png', 'spectrograms/spectrogram_0473.png', 'spectrograms/spectrogram_0474.png', 'spectrograms/spectrogram_0475.png', 'spectrograms/spectrogram_0476.png', 'spectrograms/spectrogram_0477.png', 'spectrograms/spectrogram_0478.png', 'spectrograms/spectrogram_0479.png', 'spectrograms/spectrogram_0480.png', 'spectrograms/spectrogram_0481.png', 'spectrograms/spectrogram_0482.png', 'spectrograms/spectrogram_0483.png', 'spectrograms/spectrogram_0484.png', 'spectrograms/spectrogram_0485.png', 'spectrograms/spectrogram_0486.png', 'spectrograms/spectrogram_0487.png', 'spectrograms/spectrogram_0488.png', 'spectrograms/spectrogram_0489.png', 'spectrograms/spectrogram_0490.png', 'spectrograms/spectrogram_0491.png', 'spectrograms/spectrogram_0492.png', 'spectrograms/spectrogram_0493.png', 'spectrograms/spectrogram_0494.png', 'spectrograms/spectrogram_0495.png', 'spectrograms/spectrogram_0496.png', 'spectrograms/spectrogram_0497.png', 'spectrograms/spectrogram_0498.png', 'spectrograms/spectrogram_0499.png', 'spectrograms/spectrogram_0500.png', 'spectrograms/spectrogram_0501.png', 'spectrograms/spectrogram_0502.png', 'spectrograms/spectrogram_0503.png', 'spectrograms/spectrogram_0504.png', 'spectrograms/spectrogram_0505.png', 'spectrograms/spectrogram_0506.png', 'spectrograms/spectrogram_0507.png', 'spectrograms/spectrogram_0508.png', 'spectrograms/spectrogram_0509.png', 'spectrograms/spectrogram_0510.png', 'spectrograms/spectrogram_0511.png', 'spectrograms/spectrogram_0512.png', 'spectrograms/spectrogram_0513.png', 'spectrograms/spectrogram_0514.png', 'spectrograms/spectrogram_0515.png', 'spectrograms/spectrogram_0516.png', 'spectrograms/spectrogram_0517.png', 'spectrograms/spectrogram_0518.png', 'spectrograms/spectrogram_0519.png', 'spectrograms/spectrogram_0520.png', 'spectrograms/spectrogram_0521.png', 'spectrograms/spectrogram_0522.png', 'spectrograms/spectrogram_0523.png', 'spectrograms/spectrogram_0524.png', 'spectrograms/spectrogram_0525.png', 'spectrograms/spectrogram_0526.png', 'spectrograms/spectrogram_0527.png', 'spectrograms/spectrogram_0528.png', 'spectrograms/spectrogram_0529.png', 'spectrograms/spectrogram_0530.png', 'spectrograms/spectrogram_0531.png', 'spectrograms/spectrogram_0532.png', 'spectrograms/spectrogram_0533.png', 'spectrograms/spectrogram_0534.png', 'spectrograms/spectrogram_0535.png', 'spectrograms/spectrogram_0536.png', 'spectrograms/spectrogram_0537.png', 'spectrograms/spectrogram_0538.png', 'spectrograms/spectrogram_0539.png', 'spectrograms/spectrogram_0540.png', 'spectrograms/spectrogram_0541.png', 'spectrograms/spectrogram_0542.png', 'spectrograms/spectrogram_0543.png', 'spectrograms/spectrogram_0544.png', 'spectrograms/spectrogram_0545.png', 'spectrograms/spectrogram_0546.png', 'spectrograms/spectrogram_0547.png', 'spectrograms/spectrogram_0548.png', 'spectrograms/spectrogram_0549.png', 'spectrograms/spectrogram_0550.png', 'spectrograms/spectrogram_0551.png', 'spectrograms/spectrogram_0552.png', 'spectrograms/spectrogram_0553.png', 'spectrograms/spectrogram_0554.png', 'spectrograms/spectrogram_0555.png', 'spectrograms/spectrogram_0556.png', 'spectrograms/spectrogram_0557.png', 'spectrograms/spectrogram_0558.png', 'spectrograms/spectrogram_0559.png', 'spectrograms/spectrogram_0560.png', 'spectrograms/spectrogram_0561.png', 'spectrograms/spectrogram_0562.png', 'spectrograms/spectrogram_0563.png', 'spectrograms/spectrogram_0564.png', 'spectrograms/spectrogram_0565.png', 'spectrograms/spectrogram_0566.png', 'spectrograms/spectrogram_0567.png', 'spectrograms/spectrogram_0568.png', 'spectrograms/spectrogram_0569.png', 'spectrograms/spectrogram_0570.png', 'spectrograms/spectrogram_0571.png', 'spectrograms/spectrogram_0572.png', 'spectrograms/spectrogram_0573.png', 'spectrograms/spectrogram_0574.png', 'spectrograms/spectrogram_0575.png', 'spectrograms/spectrogram_0576.png', 'spectrograms/spectrogram_0577.png', 'spectrograms/spectrogram_0578.png', 'spectrograms/spectrogram_0579.png', 'spectrograms/spectrogram_0580.png', 'spectrograms/spectrogram_0581.png', 'spectrograms/spectrogram_0582.png', 'spectrograms/spectrogram_0583.png', 'spectrograms/spectrogram_0584.png', 'spectrograms/spectrogram_0585.png', 'spectrograms/spectrogram_0586.png', 'spectrograms/spectrogram_0587.png', 'spectrograms/spectrogram_0588.png', 'spectrograms/spectrogram_0589.png', 'spectrograms/spectrogram_0590.png', 'spectrograms/spectrogram_0591.png', 'spectrograms/spectrogram_0592.png', 'spectrograms/spectrogram_0593.png', 'spectrograms/spectrogram_0594.png', 'spectrograms/spectrogram_0595.png', 'spectrograms/spectrogram_0596.png', 'spectrograms/spectrogram_0597.png', 'spectrograms/spectrogram_0598.png', 'spectrograms/spectrogram_0599.png', 'spectrograms/spectrogram_0600.png', 'spectrograms/spectrogram_0601.png', 'spectrograms/spectrogram_0602.png', 'spectrograms/spectrogram_0603.png', 'spectrograms/spectrogram_0604.png', 'spectrograms/spectrogram_0605.png', 'spectrograms/spectrogram_0606.png', 'spectrograms/spectrogram_0607.png', 'spectrograms/spectrogram_0608.png', 'spectrograms/spectrogram_0609.png', 'spectrograms/spectrogram_0610.png', 'spectrograms/spectrogram_0611.png', 'spectrograms/spectrogram_0612.png', 'spectrograms/spectrogram_0613.png', 'spectrograms/spectrogram_0614.png', 'spectrograms/spectrogram_0615.png', 'spectrograms/spectrogram_0616.png', 'spectrograms/spectrogram_0617.png', 'spectrograms/spectrogram_0618.png', 'spectrograms/spectrogram_0619.png', 'spectrograms/spectrogram_0620.png', 'spectrograms/spectrogram_0621.png', 'spectrograms/spectrogram_0622.png', 'spectrograms/spectrogram_0623.png', 'spectrograms/spectrogram_0624.png', 'spectrograms/spectrogram_0625.png', 'spectrograms/spectrogram_0626.png', 'spectrograms/spectrogram_0627.png', 'spectrograms/spectrogram_0628.png', 'spectrograms/spectrogram_0629.png', 'spectrograms/spectrogram_0630.png', 'spectrograms/spectrogram_0631.png', 'spectrograms/spectrogram_0632.png', 'spectrograms/spectrogram_0633.png', 'spectrograms/spectrogram_0634.png', 'spectrograms/spectrogram_0635.png', 'spectrograms/spectrogram_0636.png', 'spectrograms/spectrogram_0637.png', 'spectrograms/spectrogram_0638.png', 'spectrograms/spectrogram_0639.png', 'spectrograms/spectrogram_0640.png', 'spectrograms/spectrogram_0641.png', 'spectrograms/spectrogram_0642.png', 'spectrograms/spectrogram_0643.png', 'spectrograms/spectrogram_0644.png', 'spectrograms/spectrogram_0645.png', 'spectrograms/spectrogram_0646.png', 'spectrograms/spectrogram_0647.png', 'spectrograms/spectrogram_0648.png', 'spectrograms/spectrogram_0649.png', 'spectrograms/spectrogram_0650.png', 'spectrograms/spectrogram_0651.png', 'spectrograms/spectrogram_0652.png', 'spectrograms/spectrogram_0653.png', 'spectrograms/spectrogram_0654.png', 'spectrograms/spectrogram_0655.png', 'spectrograms/spectrogram_0656.png', 'spectrograms/spectrogram_0657.png', 'spectrograms/spectrogram_0658.png', 'spectrograms/spectrogram_0659.png', 'spectrograms/spectrogram_0660.png', 'spectrograms/spectrogram_0661.png', 'spectrograms/spectrogram_0662.png', 'spectrograms/spectrogram_0663.png', 'spectrograms/spectrogram_0664.png', 'spectrograms/spectrogram_0665.png', 'spectrograms/spectrogram_0666.png', 'spectrograms/spectrogram_0667.png', 'spectrograms/spectrogram_0668.png', 'spectrograms/spectrogram_0669.png', 'spectrograms/spectrogram_0670.png', 'spectrograms/spectrogram_0671.png', 'spectrograms/spectrogram_0672.png', 'spectrograms/spectrogram_0673.png', 'spectrograms/spectrogram_0674.png', 'spectrograms/spectrogram_0675.png', 'spectrograms/spectrogram_0676.png', 'spectrograms/spectrogram_0677.png', 'spectrograms/spectrogram_0678.png', 'spectrograms/spectrogram_0679.png', 'spectrograms/spectrogram_0680.png', 'spectrograms/spectrogram_0681.png', 'spectrograms/spectrogram_0682.png', 'spectrograms/spectrogram_0683.png', 'spectrograms/spectrogram_0684.png', 'spectrograms/spectrogram_0685.png', 'spectrograms/spectrogram_0686.png', 'spectrograms/spectrogram_0687.png', 'spectrograms/spectrogram_0688.png', 'spectrograms/spectrogram_0689.png', 'spectrograms/spectrogram_0690.png', 'spectrograms/spectrogram_0691.png', 'spectrograms/spectrogram_0692.png', 'spectrograms/spectrogram_0693.png', 'spectrograms/spectrogram_0694.png', 'spectrograms/spectrogram_0695.png', 'spectrograms/spectrogram_0696.png', 'spectrograms/spectrogram_0697.png', 'spectrograms/spectrogram_0698.png', 'spectrograms/spectrogram_0699.png', 'spectrograms/spectrogram_0700.png', 'spectrograms/spectrogram_0701.png', 'spectrograms/spectrogram_0702.png', 'spectrograms/spectrogram_0703.png', 'spectrograms/spectrogram_0704.png', 'spectrograms/spectrogram_0705.png', 'spectrograms/spectrogram_0706.png', 'spectrograms/spectrogram_0707.png', 'spectrograms/spectrogram_0708.png', 'spectrograms/spectrogram_0709.png', 'spectrograms/spectrogram_0710.png', 'spectrograms/spectrogram_0711.png', 'spectrograms/spectrogram_0712.png', 'spectrograms/spectrogram_0713.png', 'spectrograms/spectrogram_0714.png', 'spectrograms/spectrogram_0715.png', 'spectrograms/spectrogram_0716.png', 'spectrograms/spectrogram_0717.png', 'spectrograms/spectrogram_0718.png', 'spectrograms/spectrogram_0719.png', 'spectrograms/spectrogram_0720.png', 'spectrograms/spectrogram_0721.png', 'spectrograms/spectrogram_0722.png', 'spectrograms/spectrogram_0723.png', 'spectrograms/spectrogram_0724.png', 'spectrograms/spectrogram_0725.png', 'spectrograms/spectrogram_0726.png', 'spectrograms/spectrogram_0727.png', 'spectrograms/spectrogram_0728.png', 'spectrograms/spectrogram_0729.png', 'spectrograms/spectrogram_0730.png', 'spectrograms/spectrogram_0731.png', 'spectrograms/spectrogram_0732.png', 'spectrograms/spectrogram_0733.png', 'spectrograms/spectrogram_0734.png', 'spectrograms/spectrogram_0735.png', 'spectrograms/spectrogram_0736.png', 'spectrograms/spectrogram_0737.png', 'spectrograms/spectrogram_0738.png', 'spectrograms/spectrogram_0739.png', 'spectrograms/spectrogram_0740.png', 'spectrograms/spectrogram_0741.png', 'spectrograms/spectrogram_0742.png', 'spectrograms/spectrogram_0743.png', 'spectrograms/spectrogram_0744.png', 'spectrograms/spectrogram_0745.png', 'spectrograms/spectrogram_0746.png', 'spectrograms/spectrogram_0747.png', 'spectrograms/spectrogram_0748.png', 'spectrograms/spectrogram_0749.png', 'spectrograms/spectrogram_0750.png', 'spectrograms/spectrogram_0751.png', 'spectrograms/spectrogram_0752.png', 'spectrograms/spectrogram_0753.png', 'spectrograms/spectrogram_0754.png', 'spectrograms/spectrogram_0755.png', 'spectrograms/spectrogram_0756.png', 'spectrograms/spectrogram_0757.png', 'spectrograms/spectrogram_0758.png', 'spectrograms/spectrogram_0759.png', 'spectrograms/spectrogram_0760.png', 'spectrograms/spectrogram_0761.png', 'spectrograms/spectrogram_0762.png', 'spectrograms/spectrogram_0763.png', 'spectrograms/spectrogram_0764.png', 'spectrograms/spectrogram_0765.png', 'spectrograms/spectrogram_0766.png', 'spectrograms/spectrogram_0767.png', 'spectrograms/spectrogram_0768.png', 'spectrograms/spectrogram_0769.png', 'spectrograms/spectrogram_0770.png', 'spectrograms/spectrogram_0771.png', 'spectrograms/spectrogram_0772.png', 'spectrograms/spectrogram_0773.png', 'spectrograms/spectrogram_0774.png', 'spectrograms/spectrogram_0775.png', 'spectrograms/spectrogram_0776.png', 'spectrograms/spectrogram_0777.png', 'spectrograms/spectrogram_0778.png', 'spectrograms/spectrogram_0779.png', 'spectrograms/spectrogram_0780.png', 'spectrograms/spectrogram_0781.png', 'spectrograms/spectrogram_0782.png', 'spectrograms/spectrogram_0783.png', 'spectrograms/spectrogram_0784.png', 'spectrograms/spectrogram_0785.png', 'spectrograms/spectrogram_0786.png', 'spectrograms/spectrogram_0787.png', 'spectrograms/spectrogram_0788.png', 'spectrograms/spectrogram_0789.png', 'spectrograms/spectrogram_0790.png', 'spectrograms/spectrogram_0791.png', 'spectrograms/spectrogram_0792.png', 'spectrograms/spectrogram_0793.png', 'spectrograms/spectrogram_0794.png', 'spectrograms/spectrogram_0795.png', 'spectrograms/spectrogram_0796.png', 'spectrograms/spectrogram_0797.png', 'spectrograms/spectrogram_0798.png', 'spectrograms/spectrogram_0799.png', 'spectrograms/spectrogram_0800.png', 'spectrograms/spectrogram_0801.png', 'spectrograms/spectrogram_0802.png', 'spectrograms/spectrogram_0803.png', 'spectrograms/spectrogram_0804.png', 'spectrograms/spectrogram_0805.png', 'spectrograms/spectrogram_0806.png', 'spectrograms/spectrogram_0807.png', 'spectrograms/spectrogram_0808.png', 'spectrograms/spectrogram_0809.png', 'spectrograms/spectrogram_0810.png', 'spectrograms/spectrogram_0811.png', 'spectrograms/spectrogram_0812.png', 'spectrograms/spectrogram_0813.png', 'spectrograms/spectrogram_0814.png', 'spectrograms/spectrogram_0815.png', 'spectrograms/spectrogram_0816.png', 'spectrograms/spectrogram_0817.png', 'spectrograms/spectrogram_0818.png', 'spectrograms/spectrogram_0819.png', 'spectrograms/spectrogram_0820.png', 'spectrograms/spectrogram_0821.png', 'spectrograms/spectrogram_0822.png', 'spectrograms/spectrogram_0823.png', 'spectrograms/spectrogram_0824.png', 'spectrograms/spectrogram_0825.png', 'spectrograms/spectrogram_0826.png', 'spectrograms/spectrogram_0827.png', 'spectrograms/spectrogram_0828.png', 'spectrograms/spectrogram_0829.png', 'spectrograms/spectrogram_0830.png', 'spectrograms/spectrogram_0831.png', 'spectrograms/spectrogram_0832.png', 'spectrograms/spectrogram_0833.png', 'spectrograms/spectrogram_0834.png', 'spectrograms/spectrogram_0835.png', 'spectrograms/spectrogram_0836.png', 'spectrograms/spectrogram_0837.png', 'spectrograms/spectrogram_0838.png', 'spectrograms/spectrogram_0839.png', 'spectrograms/spectrogram_0840.png', 'spectrograms/spectrogram_0841.png', 'spectrograms/spectrogram_0842.png', 'spectrograms/spectrogram_0843.png', 'spectrograms/spectrogram_0844.png', 'spectrograms/spectrogram_0845.png', 'spectrograms/spectrogram_0846.png', 'spectrograms/spectrogram_0847.png', 'spectrograms/spectrogram_0848.png', 'spectrograms/spectrogram_0849.png', 'spectrograms/spectrogram_0850.png', 'spectrograms/spectrogram_0851.png', 'spectrograms/spectrogram_0852.png', 'spectrograms/spectrogram_0853.png', 'spectrograms/spectrogram_0854.png', 'spectrograms/spectrogram_0855.png', 'spectrograms/spectrogram_0856.png', 'spectrograms/spectrogram_0857.png', 'spectrograms/spectrogram_0858.png', 'spectrograms/spectrogram_0859.png', 'spectrograms/spectrogram_0860.png', 'spectrograms/spectrogram_0861.png', 'spectrograms/spectrogram_0862.png', 'spectrograms/spectrogram_0863.png', 'spectrograms/spectrogram_0864.png', 'spectrograms/spectrogram_0865.png', 'spectrograms/spectrogram_0866.png', 'spectrograms/spectrogram_0867.png', 'spectrograms/spectrogram_0868.png', 'spectrograms/spectrogram_0869.png', 'spectrograms/spectrogram_0870.png', 'spectrograms/spectrogram_0871.png', 'spectrograms/spectrogram_0872.png', 'spectrograms/spectrogram_0873.png', 'spectrograms/spectrogram_0874.png', 'spectrograms/spectrogram_0875.png', 'spectrograms/spectrogram_0876.png', 'spectrograms/spectrogram_0877.png', 'spectrograms/spectrogram_0878.png', 'spectrograms/spectrogram_0879.png', 'spectrograms/spectrogram_0880.png', 'spectrograms/spectrogram_0881.png', 'spectrograms/spectrogram_0882.png', 'spectrograms/spectrogram_0883.png', 'spectrograms/spectrogram_0884.png', 'spectrograms/spectrogram_0885.png', 'spectrograms/spectrogram_0886.png', 'spectrograms/spectrogram_0887.png', 'spectrograms/spectrogram_0888.png', 'spectrograms/spectrogram_0889.png', 'spectrograms/spectrogram_0890.png', 'spectrograms/spectrogram_0891.png', 'spectrograms/spectrogram_0892.png', 'spectrograms/spectrogram_0893.png', 'spectrograms/spectrogram_0894.png', 'spectrograms/spectrogram_0895.png', 'spectrograms/spectrogram_0896.png', 'spectrograms/spectrogram_0897.png', 'spectrograms/spectrogram_0898.png', 'spectrograms/spectrogram_0899.png', 'spectrograms/spectrogram_0900.png', 'spectrograms/spectrogram_0901.png', 'spectrograms/spectrogram_0902.png', 'spectrograms/spectrogram_0903.png', 'spectrograms/spectrogram_0904.png', 'spectrograms/spectrogram_0905.png', 'spectrograms/spectrogram_0906.png', 'spectrograms/spectrogram_0907.png', 'spectrograms/spectrogram_0908.png', 'spectrograms/spectrogram_0909.png', 'spectrograms/spectrogram_0910.png', 'spectrograms/spectrogram_0911.png', 'spectrograms/spectrogram_0912.png', 'spectrograms/spectrogram_0913.png', 'spectrograms/spectrogram_0914.png', 'spectrograms/spectrogram_0915.png', 'spectrograms/spectrogram_0916.png', 'spectrograms/spectrogram_0917.png', 'spectrograms/spectrogram_0918.png', 'spectrograms/spectrogram_0919.png', 'spectrograms/spectrogram_0920.png', 'spectrograms/spectrogram_0921.png', 'spectrograms/spectrogram_0922.png', 'spectrograms/spectrogram_0923.png', 'spectrograms/spectrogram_0924.png', 'spectrograms/spectrogram_0925.png', 'spectrograms/spectrogram_0926.png', 'spectrograms/spectrogram_0927.png', 'spectrograms/spectrogram_0928.png', 'spectrograms/spectrogram_0929.png', 'spectrograms/spectrogram_0930.png', 'spectrograms/spectrogram_0931.png', 'spectrograms/spectrogram_0932.png', 'spectrograms/spectrogram_0933.png', 'spectrograms/spectrogram_0934.png', 'spectrograms/spectrogram_0935.png', 'spectrograms/spectrogram_0936.png', 'spectrograms/spectrogram_0937.png', 'spectrograms/spectrogram_0938.png', 'spectrograms/spectrogram_0939.png', 'spectrograms/spectrogram_0940.png', 'spectrograms/spectrogram_0941.png', 'spectrograms/spectrogram_0942.png', 'spectrograms/spectrogram_0943.png', 'spectrograms/spectrogram_0944.png', 'spectrograms/spectrogram_0945.png', 'spectrograms/spectrogram_0946.png', 'spectrograms/spectrogram_0947.png', 'spectrograms/spectrogram_0948.png', 'spectrograms/spectrogram_0949.png', 'spectrograms/spectrogram_0950.png', 'spectrograms/spectrogram_0951.png', 'spectrograms/spectrogram_0952.png', 'spectrograms/spectrogram_0953.png', 'spectrograms/spectrogram_0954.png', 'spectrograms/spectrogram_0955.png', 'spectrograms/spectrogram_0956.png', 'spectrograms/spectrogram_0957.png', 'spectrograms/spectrogram_0958.png', 'spectrograms/spectrogram_0959.png', 'spectrograms/spectrogram_0960.png', 'spectrograms/spectrogram_0961.png', 'spectrograms/spectrogram_0962.png', 'spectrograms/spectrogram_0963.png', 'spectrograms/spectrogram_0964.png', 'spectrograms/spectrogram_0965.png', 'spectrograms/spectrogram_0966.png', 'spectrograms/spectrogram_0967.png', 'spectrograms/spectrogram_0968.png', 'spectrograms/spectrogram_0969.png', 'spectrograms/spectrogram_0970.png', 'spectrograms/spectrogram_0971.png', 'spectrograms/spectrogram_0972.png', 'spectrograms/spectrogram_0973.png', 'spectrograms/spectrogram_0974.png', 'spectrograms/spectrogram_0975.png', 'spectrograms/spectrogram_0976.png', 'spectrograms/spectrogram_0977.png', 'spectrograms/spectrogram_0978.png', 'spectrograms/spectrogram_0979.png', 'spectrograms/spectrogram_0980.png', 'spectrograms/spectrogram_0981.png', 'spectrograms/spectrogram_0982.png', 'spectrograms/spectrogram_0983.png', 'spectrograms/spectrogram_0984.png', 'spectrograms/spectrogram_0985.png', 'spectrograms/spectrogram_0986.png', 'spectrograms/spectrogram_0987.png', 'spectrograms/spectrogram_0988.png', 'spectrograms/spectrogram_0989.png', 'spectrograms/spectrogram_0990.png', 'spectrograms/spectrogram_0991.png', 'spectrograms/spectrogram_0992.png', 'spectrograms/spectrogram_0993.png', 'spectrograms/spectrogram_0994.png', 'spectrograms/spectrogram_0995.png', 'spectrograms/spectrogram_0996.png', 'spectrograms/spectrogram_0997.png', 'spectrograms/spectrogram_0998.png', 'spectrograms/spectrogram_0999.png']\n"
     ]
    }
   ],
   "source": [
    "# Get access to zip-archive\n",
    "archive = zipfile.ZipFile('../data/spectrograms.zip', 'r')\n",
    "imgdata = archive.read('spectrograms/spectrogram_0000.png')\n",
    "\n",
    "files = sorted([f for f in archive.namelist()[1:] if f.startswith('spectrograms/') and f.endswith('.png')])\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JFF: Get a feeling for the nature of the training and evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL IMAGE:\n",
      "Type of image:\n",
      "<class 'numpy.ndarray'>\n",
      "Dimension of a single image file:\n",
      "(128, 128, 3)\n",
      "TRANSPOSED IMAGE:\n",
      "Type of image:\n",
      "<class 'numpy.ndarray'>\n",
      "Dimension of a single image file:\n",
      "(128, 128, 3)\n",
      "\n",
      "\n",
      "... Full pipeline demonstration ...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interpret image-data as image\n",
    "image = cv2.imdecode(np.frombuffer(imgdata, dtype=np.uint8), 1)\n",
    "\n",
    "# Get data and visual representation of original image\n",
    "print('ORIGINAL IMAGE:')\n",
    "print('Type of image:')\n",
    "print(type(image))\n",
    "print('Dimension of a single image file:')\n",
    "print(image.shape)\n",
    "\n",
    "# Show image visually (press any key in opening window in order to proceed in code...)\n",
    "cv2.imshow(\"Image\", image)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# Transpose image and repeat the above...\n",
    "#order_after_transpose = [1,0,2]\n",
    "#image = np.transpose(image, axes=order_after_transpose)\n",
    "image = np.rot90(image, 3) # Rotate 3* by 90° (each) \n",
    "print('TRANSPOSED IMAGE:')\n",
    "print('Type of image:')\n",
    "print(type(image))\n",
    "print('Dimension of a single image file:')\n",
    "print(image.shape)\n",
    "\n",
    "cv2.imshow(\"Image transposed\", image)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "print('\\n\\n... Full pipeline demonstration ...\\n\\n')\n",
    "\n",
    "##### FULL READ-IN-PIPELINE:\n",
    "# Interpret image-data as image\n",
    "image = cv2.imdecode(np.frombuffer(imgdata, dtype=np.uint8), 1)\n",
    "\n",
    "# Normalize image's colors to range [0, 1]\n",
    "image = image / 255.0\n",
    "\n",
    "# Rotate by 270° (=3*90°) \n",
    "image = np.rot90(image, 3)\n",
    "\n",
    "# Grayscale image\n",
    "gray_image = skimage.color.rgb2gray(image)\n",
    "\n",
    "cv2.imshow(\"Final Image\", gray_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in both training and testing data from zip archive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading in... Shape of data array:\n",
      "(1000, 128, 128)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data_set = []\n",
    "# Data storage\n",
    "combined_data = np.empty([1, 128, 128])\n",
    "\n",
    "# Read in images & store processed instances\n",
    "for f_name in files:\n",
    "    # Get image data from zip file\n",
    "    zip_img_data = archive.read(f_name)\n",
    "    image = cv2.imdecode(np.frombuffer(zip_img_data, dtype=np.uint8), 1)\n",
    "    \n",
    "    # Normalize image's colors to range [0, 1]\n",
    "    image = image / 255.0\n",
    "    \n",
    "    # Rotate by 270° (=3*90°) \n",
    "    image = np.rot90(image, 3)\n",
    "    \n",
    "    # Grayscale image\n",
    "    gray_image = skimage.color.rgb2gray(image)\n",
    "\n",
    "    # Store grayscaled image\n",
    "    combined_data = np.append(combined_data, [gray_image], axis=0)\n",
    "    \n",
    "# Remove initial, empty datapoint\n",
    "combined_data = combined_data[1:, :, :]\n",
    "\n",
    "print('Done reading in... Shape of data array:')\n",
    "print(combined_data.shape)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
      " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
      " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5. 5.\n",
      " 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6.\n",
      " 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6.\n",
      " 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6.\n",
      " 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6. 6.\n",
      " 6. 6. 6. 6. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7.\n",
      " 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7.\n",
      " 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7.\n",
      " 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7. 7.\n",
      " 7. 7. 7. 7. 7. 7. 7. 7. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8.\n",
      " 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8.\n",
      " 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8.\n",
      " 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8.\n",
      " 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 8. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9.\n",
      " 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9.\n",
      " 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9.\n",
      " 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9.\n",
      " 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "labels_path = '../data/labels.txt'\n",
    "\n",
    "combined_labels = np.empty([1])\n",
    "\n",
    "with open(labels_path, 'r') as file:\n",
    "    for line in file:\n",
    "        combined_labels = np.append(combined_labels, [int(line)])\n",
    "\n",
    "# Remove initial, empty datapoint\n",
    "combined_labels = combined_labels[1:] \n",
    "print(combined_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide data into train and test data:\n",
    "\n",
    "------------------------------------------------------\n",
    "Training data will be contained in:    training_data\n",
    "Tetsing  data will be contained in:    testing_data\n",
    "\n",
    "Training labels will be contained in:  training_labels\n",
    "Tetsing  labels will be contained in:  testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr. test indices: 150\n",
      "Test indices: [2, 4, 17, 22, 26, 29, 34, 48, 53, 81, 83, 117, 125, 129, 132, 133, 136, 149, 161, 162, 166, 186, 192, 193, 200, 209, 213, 214, 215, 221, 222, 231, 242, 247, 259, 263, 270, 280, 286, 293, 304, 316, 326, 328, 331, 337, 342, 350, 358, 363, 366, 368, 382, 407, 409, 424, 425, 426, 435, 437, 446, 451, 459, 472, 487, 493, 497, 503, 521, 526, 527, 532, 533, 538, 542, 546, 548, 560, 567, 573, 577, 578, 594, 596, 603, 605, 609, 623, 629, 632, 642, 650, 659, 667, 675, 685, 692, 695, 697, 709, 710, 711, 714, 726, 730, 731, 743, 748, 749, 751, 759, 764, 768, 776, 778, 779, 780, 785, 787, 803, 808, 810, 833, 834, 837, 842, 843, 846, 856, 859, 862, 889, 896, 897, 898, 906, 913, 916, 917, 925, 938, 945, 950, 961, 969, 971, 980, 985, 993, 994]\n",
      "Final:\n",
      "(850, 128, 128)\n",
      "(850,)\n",
      "(150, 128, 128)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "# Get set of test-indices which indicates the training data points that have to be reserved for training\n",
    "percentage_test_data = 0.15\n",
    "population = range(len(combined_labels))\n",
    "nr_samples = int(percentage_test_data * len(combined_labels))\n",
    "\n",
    "test_indices = random.sample(population, nr_samples)\n",
    "test_indices = sorted(test_indices)\n",
    "\n",
    "print('Nr. test indices: ' + str(len(test_indices)))\n",
    "print('Test indices: ' + str(test_indices))\n",
    "\n",
    "\n",
    "# Split data into training- and test data, respectively - Preparation: Create empty arrays in which to later insert data\n",
    "test_len = len(test_indices)\n",
    "train_len = len(combined_labels)-len(test_indices)\n",
    "training_data, training_labels = np.empty([train_len, 128, 128]), np.empty([train_len])\n",
    "testing_data, testing_labels = np.empty([test_len, 128, 128]), np.empty([test_len])\n",
    "\n",
    "test_idx_list_idx = 0\n",
    "i = 0\n",
    "\n",
    "# Iterate through all data and assign each data point either to training data or testing data\n",
    "for data_idx in range(len(combined_labels)):\n",
    "\n",
    "    if test_idx_list_idx < nr_samples and data_idx == test_indices[test_idx_list_idx]:\n",
    "        testing_data[test_idx_list_idx, :, :] = combined_data[data_idx, :, :]\n",
    "        testing_labels[test_idx_list_idx] = combined_labels[data_idx]\n",
    "        test_idx_list_idx += 1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        training_data[i, :, :] = combined_data[data_idx, :, :]\n",
    "        training_labels[i] = combined_labels[data_idx]\n",
    "        i += 1\n",
    "        \n",
    "\n",
    "# NOT FOR RNN architecture!\n",
    "#training_data = training_data.reshape([len(training_labels), 128, 128, 1])\n",
    "#testing_data = testing_data.reshape([len(testing_labels), 128, 128, 1])\n",
    "        \n",
    "print('Final:')\n",
    "print(training_data.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_data.shape)\n",
    "print(testing_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the RNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, None, 128)         32896     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 136,970\n",
      "Trainable params: 136,970\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reset tf sessions\n",
    "tf.keras.backend.clear_session()  # Destroys the current TF graph and creates a new one.\n",
    "\n",
    "dimensions = 128  # Input dimension: 128x128\n",
    "units = 128       # Dimensionality of RNN output tensor\n",
    "classes = 10      # Number of output nodes in final layers (=nr of distinct classes)\n",
    "\n",
    "# Set up model architecture in terms of its layers\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.SimpleRNN(units, input_shape=(None, dimensions),\n",
    "                           kernel_regularizer=regularizers.l2(0.001),\n",
    "                           recurrent_regularizer=regularizers.l2(0.001),\n",
    "                           bias_regularizer=regularizers.l2(0.001), return_sequences=True  #return_sequences = 1 output of dim=units per time-step/(=here:row)\n",
    "         )) #Alternatively: layers.SimpleRNN || layers.LSTM || layers.GRU\n",
    "\n",
    "model.add(layers.SimpleRNN(units, input_shape=(None, dimensions),\n",
    "                           kernel_regularizer=regularizers.l2(0.001),\n",
    "                           recurrent_regularizer=regularizers.l2(0.001),\n",
    "                           bias_regularizer=regularizers.l2(0.001)\n",
    "         )) #Alternatively: layers.SimpleRNN || layers.LSTM || layers.GRU\n",
    "\n",
    "# The output of GRU will be a 3D tensor of shape (batch_size, 256):\n",
    "#model.add(layers.GRU(256))\n",
    "\n",
    "\n",
    "#model.add(layers.Dropout(0.1))\n",
    "\n",
    "model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.03)))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(classes, activation='softmax'))\n",
    "\n",
    "# Note on regularizer(s), copied from https://www.tensorflow.org/tutorials/keras/overfit_and_underfit:\n",
    "# l2(0.001) means that every coefficient in the weight matrix of the layer will add 0.001 * weight_coefficient_value**2\n",
    "# to the total loss of the network.\n",
    "\n",
    "# Print summary\n",
    "model.summary()\n",
    "\n",
    "# Compile model & make some design choices\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001, #0.001\n",
    "                                           beta_1=0.9,\n",
    "                                           beta_2=0.999,\n",
    "                                           epsilon=1e-07,\n",
    "                                           amsgrad=False,\n",
    "                                           name='Adam'\n",
    "                                           ),\n",
    "              loss='sparse_categorical_crossentropy',  # Capable of working with regularization\n",
    "              metrics=['accuracy', 'sparse_categorical_crossentropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute training:\n",
    "\n",
    "Start training process:\n",
    "    Run X times Y tensorflow-epochs and save a model as checkpoint after any Y epochs. \n",
    "    FIXME: Bit hacky solution, yet, but can be prettyfied.\n",
    "    \n",
    "IMPORTANT: 'accuracy'     == accuracy achieved during training on training data;  * the UN-important measure\n",
    "           'val_accuracy' == accuracy achieved on TEST data AFTER training epoch; * the important measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epochs so far: 0\n",
      "Train on 850 samples, validate on 150 samples\n",
      "Epoch 1/10\n",
      "850/850 [==============================] - 3s 4ms/sample - loss: 7.4685 - accuracy: 0.1224 - sparse_categorical_crossentropy: 2.3154 - val_loss: 5.9709 - val_accuracy: 0.2200 - val_sparse_categorical_crossentropy: 2.1812\n",
      "Epoch 2/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 5.1741 - accuracy: 0.1988 - sparse_categorical_crossentropy: 2.1854 - val_loss: 4.4393 - val_accuracy: 0.1733 - val_sparse_categorical_crossentropy: 2.1655\n",
      "Epoch 3/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 4.0080 - accuracy: 0.1788 - sparse_categorical_crossentropy: 2.1534 - val_loss: 3.6461 - val_accuracy: 0.2067 - val_sparse_categorical_crossentropy: 2.1680\n",
      "Epoch 4/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 3.3700 - accuracy: 0.2094 - sparse_categorical_crossentropy: 2.1188 - val_loss: 3.1843 - val_accuracy: 0.1933 - val_sparse_categorical_crossentropy: 2.1368\n",
      "Epoch 5/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.9087 - accuracy: 0.2612 - sparse_categorical_crossentropy: 1.9813 - val_loss: 3.0633 - val_accuracy: 0.2000 - val_sparse_categorical_crossentropy: 2.2459\n",
      "Epoch 6/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.7099 - accuracy: 0.2835 - sparse_categorical_crossentropy: 1.9603 - val_loss: 3.0031 - val_accuracy: 0.1667 - val_sparse_categorical_crossentropy: 2.3158\n",
      "Epoch 7/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.6679 - accuracy: 0.2706 - sparse_categorical_crossentropy: 2.0211 - val_loss: 2.7952 - val_accuracy: 0.2133 - val_sparse_categorical_crossentropy: 2.1836\n",
      "Epoch 8/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.5473 - accuracy: 0.3024 - sparse_categorical_crossentropy: 1.9576 - val_loss: 2.5334 - val_accuracy: 0.3133 - val_sparse_categorical_crossentropy: 1.9614\n",
      "Epoch 9/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.3643 - accuracy: 0.3588 - sparse_categorical_crossentropy: 1.7993 - val_loss: 2.6832 - val_accuracy: 0.2067 - val_sparse_categorical_crossentropy: 2.1257\n",
      "Epoch 10/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.4699 - accuracy: 0.2953 - sparse_categorical_crossentropy: 1.9268 - val_loss: 2.5761 - val_accuracy: 0.2667 - val_sparse_categorical_crossentropy: 2.0485\n",
      "Completed epochs so far: 10\n",
      "Train on 850 samples, validate on 150 samples\n",
      "Epoch 1/10\n",
      "850/850 [==============================] - 3s 4ms/sample - loss: 2.3940 - accuracy: 0.3200 - sparse_categorical_crossentropy: 1.8707 - val_loss: 2.5849 - val_accuracy: 0.2400 - val_sparse_categorical_crossentropy: 2.0668\n",
      "Epoch 2/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.2877 - accuracy: 0.3565 - sparse_categorical_crossentropy: 1.7668 - val_loss: 2.4875 - val_accuracy: 0.2867 - val_sparse_categorical_crossentropy: 1.9669\n",
      "Epoch 3/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.2418 - accuracy: 0.3894 - sparse_categorical_crossentropy: 1.7204 - val_loss: 2.5963 - val_accuracy: 0.2600 - val_sparse_categorical_crossentropy: 2.0749\n",
      "Epoch 4/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.2588 - accuracy: 0.3588 - sparse_categorical_crossentropy: 1.7397 - val_loss: 2.5845 - val_accuracy: 0.2267 - val_sparse_categorical_crossentropy: 2.0683\n",
      "Epoch 5/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.2290 - accuracy: 0.3988 - sparse_categorical_crossentropy: 1.7100 - val_loss: 2.5905 - val_accuracy: 0.2600 - val_sparse_categorical_crossentropy: 2.0698\n",
      "Epoch 6/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.1467 - accuracy: 0.4376 - sparse_categorical_crossentropy: 1.6239 - val_loss: 2.6230 - val_accuracy: 0.2933 - val_sparse_categorical_crossentropy: 2.0999\n",
      "Epoch 7/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 2.0786 - accuracy: 0.4588 - sparse_categorical_crossentropy: 1.5465 - val_loss: 2.6842 - val_accuracy: 0.2867 - val_sparse_categorical_crossentropy: 2.1498\n",
      "Epoch 8/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 1.9979 - accuracy: 0.5024 - sparse_categorical_crossentropy: 1.4582 - val_loss: 2.7321 - val_accuracy: 0.2667 - val_sparse_categorical_crossentropy: 2.1901\n",
      "Epoch 9/10\n",
      "850/850 [==============================] - 2s 2ms/sample - loss: 1.9907 - accuracy: 0.4965 - sparse_categorical_crossentropy: 1.4476 - val_loss: 2.6344 - val_accuracy: 0.3267 - val_sparse_categorical_crossentropy: 2.0881\n",
      "Epoch 10/10\n",
      "800/850 [===========================>..] - ETA: 0s - loss: 2.0483 - accuracy: 0.4661 - sparse_categorical_crossentropy: 1.5020"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f7dc7b81ffde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     history = model.fit(training_data, training_labels,\n\u001b[1;32m     37\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                         validation_data=(testing_data, testing_labels))\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Get string representation of performed number of training epochs & new model name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up folder for data gathering during training process\n",
    "now = datetime.now()\n",
    "TIME_STAMP = now.strftime(\"_%Y_%d_%m__%H_%M_%S__%f\")\n",
    "MODEL_ID = 'Model_' + TIME_STAMP + '/'\n",
    "path = 'TrainingRun/' + MODEL_ID\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Set up documentation (csv doc) of training progress\n",
    "with open(path+'training_progress.csv', 'a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"epoch\", \"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\", \"sparse_categorical_crossentropy\"])\n",
    "    file.close()\n",
    "\n",
    "\n",
    "# Save initial model - For preventing memory leaks\n",
    "name = 'cnn_model_0_acc_0'\n",
    "model.save(path+name+'.h5')\n",
    "\n",
    "# Run training\n",
    "repetitions = 10    # How many repetitions of given nr of epochs\n",
    "eps = 10            # tf-Epochs\n",
    "accuracy = 0\n",
    "min_acc = 0.85\n",
    "\n",
    "for i in range(repetitions):\n",
    "    # Live terminal update\n",
    "    print('Completed epochs so far: ' + str(i*eps))\n",
    "    \n",
    "    # Prevent memory leakage\n",
    "    tf.keras.backend.clear_session()  # Destroys the current TF graph and creates a new one.\n",
    "    model = tf.keras.models.load_model(path+name+'.h5')  # Reload model\n",
    "\n",
    "    # Perform x epochs of training\n",
    "    history = model.fit(training_data, training_labels,\n",
    "                        epochs=eps,\n",
    "                        validation_data=(testing_data, testing_labels))\n",
    "    \n",
    "    # Get string representation of performed number of training epochs & new model name\n",
    "    epoch = str((i+1)*eps)\n",
    "    name = 'cnn_model_'+epoch+'_acc_'+str(history.history['val_accuracy'])\n",
    "    \n",
    "    # Save the entire model as a checkpoint and/or final model to a HDF5 file.\n",
    "    model.save(path+name+'.h5')\n",
    "    \n",
    "    # Record training progress\n",
    "    with open(path+'training_progress.csv', 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([epoch,\n",
    "                         history.history[\"loss\"][0], \n",
    "                         history.history[\"accuracy\"][0], \n",
    "                         history.history[\"val_loss\"][0], \n",
    "                         history.history[\"val_accuracy\"][0],\n",
    "                         history.history[\"sparse_categorical_crossentropy\"][0]\n",
    "                         ])\n",
    "        file.close()\n",
    "\n",
    "    if accuracy >= min_acc and history.history['val_accuracy'][0] < accuracy:\n",
    "        # Drop in accuracy on evaluation data. Overfitting?\n",
    "        break\n",
    "    else:\n",
    "        accuracy = history.history['val_accuracy'][0]\n",
    "print('Done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
